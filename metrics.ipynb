{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EqdLv490n0ii"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import hilbert\n",
        "\n",
        "import torchaudio\n",
        "import torchaudio.functional as F\n",
        "import torchaudio.transforms as T\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import io\n",
        "import os\n",
        "import tarfile\n",
        "import tempfile\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from IPython.display import Audio\n",
        "from torchaudio.utils import download_asset\n",
        "\n",
        "import soundfile\n",
        "import ffmpeg\n",
        "\n",
        "import os\n",
        "import re\n",
        "import soundfile as sf\n",
        "import cdpam\n",
        "\n",
        "import sys\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yo2czxwHnlD"
      },
      "source": [
        "## Pattern for files goes below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "McMBIK95Hp9h"
      },
      "outputs": [],
      "source": [
        "#Pattern for files - change this to whatever pattern you want to eval\n",
        "pattern_riffusion_target = \"samples/riff-cnet-samples/spleetered/*.wav\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFM_HREOIPxl"
      },
      "source": [
        "## Run the code below, but first run the cell below that with all the functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU2OupMFHzGD"
      },
      "outputs": [],
      "source": [
        "paths = glob.glob(pattern_riffusion_target)\n",
        "print(len(paths))\n",
        "\n",
        "names = []\n",
        "\n",
        "for path in paths:\n",
        "  names.append(path.split(\".\")[0])\n",
        "\n",
        "names = sorted(list(set(names)))\n",
        "print(len(names))\n",
        "\n",
        "\n",
        "DiffImpact_losses = get_metrics(compute_DiffImpact_loss, riffusion=True)\n",
        "CDPAM_losses = get_metrics(compute_cdpam_loss, riffusion=True)\n",
        "Hilbert_losses = get_metrics(envelope_distance, riffusion=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VqwIg_JIW3U"
      },
      "outputs": [],
      "source": [
        "#Computing the mean losses\n",
        "np.mean(DiffImpact_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kwuBZHNHr9c"
      },
      "source": [
        "## All functions Below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "c5zhjPkCoFHw"
      },
      "outputs": [],
      "source": [
        "#riffusion flag is if we are evaluating riffusion, change it to false if we're evaluating the CNET\n",
        "def compute_loss(fcn, index, riffusion=False):\n",
        "\n",
        "  losses = np.zeros(20)\n",
        "  for i, name in enumerate(names):\n",
        "\n",
        "    target, _  = torchaudio.load(name+'._target.wav')\n",
        "    if riffusion==False:\n",
        "      sample, _ = torchaudio.load(name+'._samp_' + str(index) + \".wav\")  \n",
        "    else:\n",
        "      sample, _ = torchaudio.load(name+\"._sample.wav\")\n",
        "    \n",
        "    losses[i] = fcn(target, sample)\n",
        "\n",
        "    del target\n",
        "    del sample\n",
        "  return losses\n",
        "\n",
        "def get_metrics(fcn, riffusion=False):\n",
        "\n",
        "  if riffusion == False:\n",
        "    losses = np.zeros((20,4))\n",
        "    for i in range(4):\n",
        "      losses[:, i] = compute_loss(fcn, i)\n",
        "  else:\n",
        "    losses = compute_loss(fcn, 0, riffusion=True)\n",
        "  print(np.mean(losses))\n",
        "  return losses\n",
        "\n",
        "def envelope_distance(predicted_binaural, gt_binaural):\n",
        "    #channel1\n",
        "    pred_env_channel1 = np.abs(hilbert(predicted_binaural))\n",
        "    gt_env_channel1 = np.abs(hilbert(gt_binaural))\n",
        "    channel1_distance = np.sqrt(np.mean((gt_env_channel1 - pred_env_channel1)**2))\n",
        "    #sum the distance between two channels\n",
        "    envelope_distance = channel1_distance\n",
        "    return float(envelope_distance)\n",
        "\n",
        "#Generates a list of spectrograms functions, given a list of window sizes\n",
        "#hop_ratio - the ratio of the hop_length to the window size.\n",
        "#if the hop_ratio is p in (0,1), then the proportion of overlap between windows is 1-p.\n",
        "def gen_spectrogram_fcns(window_sizes, hop_ratio):\n",
        "    \n",
        "    spectrograms = []\n",
        "    for window_size in window_sizes:\n",
        "        spectrograms.append(\n",
        "            T.Spectrogram(\n",
        "                n_fft=window_size,\n",
        "                win_length=None,\n",
        "                hop_length=int(window_size*hop_ratio),\n",
        "                center=True,\n",
        "                pad_mode=\"reflect\",\n",
        "                power=2.0,\n",
        "            )\n",
        "        )\n",
        "    return spectrograms\n",
        "\n",
        "#Mel spectrogram\n",
        "def gen_mel_spectrogram_fcns(window_sizes, hop_ratio):\n",
        "    log_spectrograms = []\n",
        "    for window_size in window_sizes:\n",
        "        log_spectrograms.append(\n",
        "            T.MelSpectrogram(\n",
        "                n_fft=window_size,\n",
        "                win_length=None,\n",
        "                hop_length=int(window_size*hop_ratio),\n",
        "                center=True,\n",
        "                pad_mode=\"reflect\",\n",
        "                power=2.0,\n",
        "                n_mels = int(window_size/8)\n",
        "            )\n",
        "        )\n",
        "    return log_spectrograms\n",
        "\n",
        "#Weights -  how much each window size is weighted\n",
        "#mel - scales frequency axis by mel scale (logarithmic)\n",
        "#hop ratio = 1-(amount of overlap between window)\n",
        "#loss_fcn = distance metric between spectrograms\n",
        "\n",
        "\n",
        "def safe_log(x, eps=1e-7):\n",
        "\t\"\"\"Avoid taking the log of a non-positive number.\"\"\"\n",
        "\tsafe_x = torch.where(x <= eps, eps, x)\n",
        "\treturn torch.log(safe_x)\n",
        "\n",
        "    \n",
        "def compute_spectral_loss(waveform1, waveform2, mel=False, log=False,\n",
        "    window_sizes=[128, 256, 512, 1024, 2048], weights=[0.2, 0.2, 0.2, 0.2, 0.2],\n",
        "    hop_ratio=0.5, loss_fcn=nn.L1Loss()):\n",
        "    \n",
        "    assert len(window_sizes) == len(weights), \"list of lambdas and window sizes must be the same length\"\n",
        "\n",
        "    #Generates a list of spectrogram functions\n",
        "    if mel:\n",
        "        spectrogram_fcns = gen_mel_spectrogram_fcns(window_sizes, hop_ratio)\n",
        "    else:\n",
        "        spectrogram_fcns = gen_spectrogram_fcns(window_sizes, hop_ratio)\n",
        "\n",
        "    #Generates spectrograms for each window size and waveform\n",
        "    spectrograms1 = [spec(waveform1) for spec in spectrogram_fcns]\n",
        "    spectrograms2 = [spec(waveform2) for spec in spectrogram_fcns]\n",
        "\n",
        "    if log==True:\n",
        "        spectrograms1 = [safe_log(spec) for spec in spectrograms1]\n",
        "        spectrograms2 = [safe_log(spec) for spec in spectrograms2]\n",
        "\n",
        "        \n",
        "    loss = 0\n",
        "    for i in range(len(spectrograms1)):\n",
        "        loss += weights[i]*loss_fcn(spectrograms1[i], spectrograms2[i])\n",
        "\n",
        "    return loss\n",
        "\n",
        "def compute_DiffImpact_loss(waveform1, waveform2, lambda1=0.5, lambda2=0.5):\n",
        "    return (lambda1 * compute_spectral_loss(waveform1, waveform2) + lambda2*compute_spectral_loss(waveform1, waveform2, log=True)).item()\n",
        "\n",
        "\n",
        "loss_fn = cdpam.CDPAM()\n",
        "\n",
        "\n",
        "def compute_cdpam_loss(waveform1, waveform2,batch_size=4):\n",
        " \n",
        "    waveform1_np = waveform1.numpy()\n",
        "    waveform1_processed = np.round(waveform1_np.astype(float)*32768)\n",
        "    waveform1_processed = np.float32(waveform1_processed)\n",
        "\n",
        "    waveform2_np = waveform2.numpy()\n",
        "    waveform2_processed = np.round(waveform2_np.astype(float)*32768)\n",
        "    waveform2_processed = np.float32(waveform2_processed)\n",
        "\n",
        "    print(\"Tensor Size:\")\n",
        "    print(waveform1_processed.shape)\n",
        "    print(waveform2_processed.shape)\n",
        "\n",
        "    length_1 = waveform1_processed.shape[1]\n",
        "    length_2 = waveform2_processed.shape[1]\n",
        "    num_recs = waveform2_processed.shape[0]\n",
        "\n",
        "    sum = 0\n",
        "    for i in range(0, num_recs, batch_size):\n",
        "        tensor = loss_fn.forward(waveform1_processed[i:(i+batch_size)], waveform2_processed[i:(i+batch_size)])\n",
        "        sum += torch.sum(tensor).item()\n",
        "        del tensor\n",
        "        torch.cuda.empty_cache()\n",
        "        if i%100 == 0:\n",
        "            print(i)\n",
        "\n",
        "\n",
        "    average = sum/num_recs\n",
        "    del waveform1_np\n",
        "    del waveform2_np\n",
        "    del waveform1_processed\n",
        "    del waveform2_processed\n",
        "    print(average)\n",
        "    return average\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
