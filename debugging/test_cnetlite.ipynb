{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from share import *\n",
    "from cldm.model import create_model\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# add control to model (Source: from ControlNet)\n",
    "\n",
    "# assert os.path.exists(input_path), 'Input model does not exist.'\n",
    "# assert not os.path.exists(output_path), 'Output filename already exists.'\n",
    "# assert os.path.exists(os.path.dirname(output_path)), 'Output path is not valid.'\n",
    "\n",
    "def get_node_name(name, parent_name):\n",
    "    if len(name) <= len(parent_name):\n",
    "        return False, ''\n",
    "    p = name[:len(parent_name)]\n",
    "    if p != parent_name:\n",
    "        return False, ''\n",
    "    return True, name[len(parent_name):]\n",
    "\n",
    "    # pretrained_weights = torch.load(input_path)\n",
    "    # if 'state_dict' in pretrained_weights:\n",
    "    #     pretrained_weights = pretrained_weights['state_dict']\n",
    "\n",
    "    # scratch_dict = model.state_dict()\n",
    "\n",
    "    # target_dict = {}\n",
    "    # for k in scratch_dict.keys():\n",
    "    #     is_control, name = get_node_name(k, 'control_')\n",
    "    #     if is_control:\n",
    "    #         copy_k = 'model.diffusion_' + name\n",
    "    #     else:\n",
    "    #         copy_k = k\n",
    "    #     if copy_k in pretrained_weights:\n",
    "    #         target_dict[k] = pretrained_weights[copy_k].clone()\n",
    "    #     else:\n",
    "    #         target_dict[k] = scratch_dict[k].clone()\n",
    "    #         print(f'These weights are newly added: {k}')\n",
    "\n",
    "    # model.load_state_dict(target_dict, strict=True)\n",
    "    # torch.save(model.state_dict(), output_path)\n",
    "    # print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module 'xformers'. Proceeding without it.\n",
      "ControlLDM: Running in eps-prediction mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zachary/miniconda3/envs/mel-gen/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:258: LightningDeprecationWarning: `pytorch_lightning.utilities.distributed.rank_zero_only` has been deprecated in v1.8.1 and will be removed in v2.0.0. You can import it from `pytorch_lightning.utilities` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiffusionWrapper has 859.52 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Loaded model config from [./models/cldm_v15.yaml]\n",
      "loading pretrained weights\n",
      "These weights are newly added: control_model.zero_convs.0.0.weight\n",
      "These weights are newly added: control_model.zero_convs.0.0.bias\n",
      "These weights are newly added: control_model.zero_convs.1.0.weight\n",
      "These weights are newly added: control_model.zero_convs.1.0.bias\n",
      "These weights are newly added: control_model.zero_convs.2.0.weight\n",
      "These weights are newly added: control_model.zero_convs.2.0.bias\n",
      "These weights are newly added: control_model.zero_convs.3.0.weight\n",
      "These weights are newly added: control_model.zero_convs.3.0.bias\n",
      "These weights are newly added: control_model.zero_convs.4.0.weight\n",
      "These weights are newly added: control_model.zero_convs.4.0.bias\n",
      "These weights are newly added: control_model.zero_convs.5.0.weight\n",
      "These weights are newly added: control_model.zero_convs.5.0.bias\n",
      "These weights are newly added: control_model.zero_convs.6.0.weight\n",
      "These weights are newly added: control_model.zero_convs.6.0.bias\n",
      "These weights are newly added: control_model.zero_convs.7.0.weight\n",
      "These weights are newly added: control_model.zero_convs.7.0.bias\n",
      "These weights are newly added: control_model.zero_convs.8.0.weight\n",
      "These weights are newly added: control_model.zero_convs.8.0.bias\n",
      "These weights are newly added: control_model.zero_convs.9.0.weight\n",
      "These weights are newly added: control_model.zero_convs.9.0.bias\n",
      "These weights are newly added: control_model.zero_convs.10.0.weight\n",
      "These weights are newly added: control_model.zero_convs.10.0.bias\n",
      "These weights are newly added: control_model.zero_convs.11.0.weight\n",
      "These weights are newly added: control_model.zero_convs.11.0.bias\n",
      "These weights are newly added: control_model.input_hint_block.0.weight\n",
      "These weights are newly added: control_model.input_hint_block.0.bias\n",
      "These weights are newly added: control_model.input_hint_block.2.weight\n",
      "These weights are newly added: control_model.input_hint_block.2.bias\n",
      "These weights are newly added: control_model.input_hint_block.4.weight\n",
      "These weights are newly added: control_model.input_hint_block.4.bias\n",
      "These weights are newly added: control_model.input_hint_block.6.weight\n",
      "These weights are newly added: control_model.input_hint_block.6.bias\n",
      "These weights are newly added: control_model.input_hint_block.8.weight\n",
      "These weights are newly added: control_model.input_hint_block.8.bias\n",
      "These weights are newly added: control_model.input_hint_block.10.weight\n",
      "These weights are newly added: control_model.input_hint_block.10.bias\n",
      "These weights are newly added: control_model.input_hint_block.12.weight\n",
      "These weights are newly added: control_model.input_hint_block.12.bias\n",
      "These weights are newly added: control_model.input_hint_block.14.weight\n",
      "These weights are newly added: control_model.input_hint_block.14.bias\n",
      "These weights are newly added: control_model.middle_block_out.0.weight\n",
      "These weights are newly added: control_model.middle_block_out.0.bias\n"
     ]
    }
   ],
   "source": [
    "# examine full cnet model state dict\n",
    "\n",
    "input_path = \"models/cnet_riff_mdl.ckpt\"\n",
    "mdl_config_path = './models/cldm_v15.yaml'\n",
    "\n",
    "model = create_model(config_path=mdl_config_path)\n",
    "\n",
    "print(\"loading pretrained weights\")\n",
    "pretrained_weights = torch.load(input_path)\n",
    "if 'state_dict' in pretrained_weights:\n",
    "    pretrained_weights = pretrained_weights['state_dict']\n",
    "\n",
    "target_dict = {}\n",
    "scratch_dict = model.state_dict()\n",
    "for k in scratch_dict.keys():\n",
    "    is_control, name = get_node_name(k, 'control_')\n",
    "    if is_control:\n",
    "        copy_k = 'model.diffusion_' + name\n",
    "    else:\n",
    "        copy_k = k\n",
    "    if copy_k in pretrained_weights:\n",
    "        target_dict[k] = pretrained_weights[copy_k].clone()\n",
    "    else:\n",
    "        target_dict[k] = scratch_dict[k].clone()\n",
    "        print(f'These weights are newly added: {k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module 'xformers'. Proceeding without it.\n",
      "ControlLDM: Running in eps-prediction mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zachary/miniconda3/envs/mel-gen/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:258: LightningDeprecationWarning: `pytorch_lightning.utilities.distributed.rank_zero_only` has been deprecated in v1.8.1 and will be removed in v2.0.0. You can import it from `pytorch_lightning.utilities` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiffusionWrapper has 859.52 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Loaded model config from [./models/cldm_lite.yaml]\n",
      "loading pretrained weights\n",
      "These weights are newly added: control_model.input_hint_block.0.weight\n",
      "These weights are newly added: control_model.input_hint_block.0.bias\n",
      "These weights are newly added: control_model.input_hint_block.2.weight\n",
      "These weights are newly added: control_model.input_hint_block.2.bias\n",
      "These weights are newly added: control_model.input_hint_block.4.weight\n",
      "These weights are newly added: control_model.input_hint_block.4.bias\n",
      "These weights are newly added: control_model.input_hint_block.6.weight\n",
      "These weights are newly added: control_model.input_hint_block.6.bias\n",
      "These weights are newly added: control_model.input_hint_block.8.weight\n",
      "These weights are newly added: control_model.input_hint_block.8.bias\n",
      "These weights are newly added: control_model.input_hint_block.10.weight\n",
      "These weights are newly added: control_model.input_hint_block.10.bias\n",
      "These weights are newly added: control_model.input_hint_block.12.weight\n",
      "These weights are newly added: control_model.input_hint_block.12.bias\n",
      "These weights are newly added: control_model.input_blocks.1.0.weight\n",
      "These weights are newly added: control_model.input_blocks.1.0.bias\n",
      "These weights are newly added: control_model.input_blocks.2.0.weight\n",
      "These weights are newly added: control_model.input_blocks.2.0.bias\n",
      "These weights are newly added: control_model.input_blocks.3.1.weight\n",
      "These weights are newly added: control_model.input_blocks.3.1.bias\n",
      "These weights are newly added: control_model.input_blocks.4.0.weight\n",
      "These weights are newly added: control_model.input_blocks.4.0.bias\n",
      "These weights are newly added: control_model.input_blocks.5.0.weight\n",
      "These weights are newly added: control_model.input_blocks.5.0.bias\n",
      "These weights are newly added: control_model.input_blocks.6.1.weight\n",
      "These weights are newly added: control_model.input_blocks.6.1.bias\n",
      "These weights are newly added: control_model.input_blocks.7.0.weight\n",
      "These weights are newly added: control_model.input_blocks.7.0.bias\n",
      "These weights are newly added: control_model.input_blocks.8.0.weight\n",
      "These weights are newly added: control_model.input_blocks.8.0.bias\n",
      "These weights are newly added: control_model.input_blocks.9.1.weight\n",
      "These weights are newly added: control_model.input_blocks.9.1.bias\n",
      "These weights are newly added: control_model.input_blocks.10.0.weight\n",
      "These weights are newly added: control_model.input_blocks.10.0.bias\n",
      "These weights are newly added: control_model.input_blocks.11.0.weight\n",
      "These weights are newly added: control_model.input_blocks.11.0.bias\n",
      "These weights are newly added: control_model.zero_convs.0.0.weight\n",
      "These weights are newly added: control_model.zero_convs.0.0.bias\n",
      "These weights are newly added: control_model.zero_convs.1.0.weight\n",
      "These weights are newly added: control_model.zero_convs.1.0.bias\n",
      "These weights are newly added: control_model.zero_convs.2.0.weight\n",
      "These weights are newly added: control_model.zero_convs.2.0.bias\n",
      "These weights are newly added: control_model.zero_convs.3.0.weight\n",
      "These weights are newly added: control_model.zero_convs.3.0.bias\n",
      "These weights are newly added: control_model.zero_convs.4.0.weight\n",
      "These weights are newly added: control_model.zero_convs.4.0.bias\n",
      "These weights are newly added: control_model.zero_convs.5.0.weight\n",
      "These weights are newly added: control_model.zero_convs.5.0.bias\n",
      "These weights are newly added: control_model.zero_convs.6.0.weight\n",
      "These weights are newly added: control_model.zero_convs.6.0.bias\n",
      "These weights are newly added: control_model.zero_convs.7.0.weight\n",
      "These weights are newly added: control_model.zero_convs.7.0.bias\n",
      "These weights are newly added: control_model.zero_convs.8.0.weight\n",
      "These weights are newly added: control_model.zero_convs.8.0.bias\n",
      "These weights are newly added: control_model.zero_convs.9.0.weight\n",
      "These weights are newly added: control_model.zero_convs.9.0.bias\n",
      "These weights are newly added: control_model.zero_convs.10.0.weight\n",
      "These weights are newly added: control_model.zero_convs.10.0.bias\n",
      "These weights are newly added: control_model.zero_convs.11.0.weight\n",
      "These weights are newly added: control_model.zero_convs.11.0.bias\n",
      "These weights are newly added: control_model.middle_block.0.weight\n",
      "These weights are newly added: control_model.middle_block.0.bias\n",
      "These weights are newly added: control_model.middle_block_out.0.weight\n",
      "These weights are newly added: control_model.middle_block_out.0.bias\n"
     ]
    }
   ],
   "source": [
    "# examine full cnet model state dict\n",
    "\n",
    "input_path = \"models/cnet_riff_mdl.ckpt\"\n",
    "mdl_config_path = './models/cldm_lite.yaml'\n",
    "\n",
    "model = create_model(config_path=mdl_config_path)\n",
    "\n",
    "print(\"loading pretrained weights\")\n",
    "pretrained_weights = torch.load(input_path)\n",
    "if 'state_dict' in pretrained_weights:\n",
    "    pretrained_weights = pretrained_weights['state_dict']\n",
    "\n",
    "target_dict = {}\n",
    "scratch_dict = model.state_dict()\n",
    "for k in scratch_dict.keys():\n",
    "    is_control, name = get_node_name(k, 'control_')\n",
    "    if is_control:\n",
    "        copy_k = 'model.diffusion_' + name\n",
    "    else:\n",
    "        copy_k = k\n",
    "    if copy_k in pretrained_weights:\n",
    "        target_dict[k] = pretrained_weights[copy_k].clone()\n",
    "    else:\n",
    "        target_dict[k] = scratch_dict[k].clone()\n",
    "        print(f'These weights are newly added: {k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    cntrl_riff_path = \"./models/control_riffusion_ini.ckpt\"\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "\n",
    "    riffusion_path = hf_hub_download(repo_id=\"riffusion/riffusion-model-v1\", filename=\"riffusion-model-v1.ckpt\")\n",
    "    print(F\"Riffusion .ckpt saved to {riffusion_path}\")\n",
    "    # add control to riffusion and save controlled model to cntrl_riff_path\n",
    "    tool_add_control(riffusion_path, cntrl_riff_path)\n",
    "    print(f\"Control added to riffusion! Model saved to {cntrl_riff_path}\")\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## development of nn module below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from ldm.modules.diffusionmodules.util import (\n",
    "    conv_nd,\n",
    "    linear,\n",
    "    zero_module,\n",
    "    timestep_embedding,\n",
    ")\n",
    "from ldm.modules.diffusionmodules.openaimodel import TimestepEmbedSequential, Downsample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnetLite(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            image_size,\n",
    "            in_channels,\n",
    "            model_channels,\n",
    "            hint_channels,\n",
    "            channel_mult=(1, 2, 4, 4),\n",
    "            conv_resample=True,\n",
    "            dims=2,\n",
    "            use_fp16=False):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.image_size = image_size\n",
    "        self.in_channels = in_channels\n",
    "        self.model_channels = model_channels\n",
    "        self.hint_channels = hint_channels\n",
    "        self.channel_mult = channel_mult\n",
    "        self.dims = dims\n",
    "        # for using convolution during downsample\n",
    "        self.conv_resample = conv_resample\n",
    "        self.dtype = torch.float16 if use_fp16 else torch.float32\n",
    "\n",
    "        # timestep embedder\n",
    "        time_embed_dim = model_channels * 4\n",
    "        self.time_embed = nn.Sequential(\n",
    "            linear(model_channels, time_embed_dim),\n",
    "            nn.SiLU(),\n",
    "            linear(time_embed_dim, time_embed_dim),\n",
    "        )\n",
    "\n",
    "        # encoder for control hint into shape [*,model_channels,64,64]\n",
    "        self.input_hint_block = TimestepEmbedSequential(\n",
    "            conv_nd(dims, hint_channels, 16, 3, padding=1),\n",
    "            nn.SiLU(),\n",
    "            conv_nd(dims, 16, 16, 3, padding=1),\n",
    "            nn.SiLU(),\n",
    "            conv_nd(dims, 16, 32, 3, padding=1, stride=2),\n",
    "            nn.SiLU(),\n",
    "            conv_nd(dims, 32, 32, 3, padding=1),\n",
    "            nn.SiLU(),\n",
    "            conv_nd(dims, 32, 96, 3, padding=1, stride=2),\n",
    "            nn.SiLU(),\n",
    "            conv_nd(dims, 96, 96, 3, padding=1),\n",
    "            nn.SiLU(),\n",
    "            conv_nd(dims, 96, 256, 3, padding=1, stride=2),\n",
    "            nn.SiLU(),\n",
    "            zero_module(conv_nd(dims, 256, model_channels, 3, padding=1))\n",
    "        )\n",
    "\n",
    "        ch = model_channels\n",
    "\n",
    "        self.input_blocks = nn.ModuleList()\n",
    "        self.zero_convs = nn.ModuleList()\n",
    "\n",
    "        # encoder layers for injections into SD model\n",
    "        for (layer, mult) in enumerate(channel_mult): \n",
    "\n",
    "            ch = model_channels * mult \n",
    "\n",
    "            if layer == 0:\n",
    "                self.input_blocks.append(self.cnet_lite_layer(ch, ch))\n",
    "                self.zero_convs.append(self.make_zero_conv(ch))\n",
    "                self.input_blocks.append(self.cnet_lite_layer(ch, ch))\n",
    "            # use previous layer multiplicity for first embedding, and downsamples image from previous layer\n",
    "            else:\n",
    "                prev_ch =  model_channels * channel_mult[layer-1]\n",
    "                self.input_blocks.append(self.cnet_lite_layer(prev_ch, prev_ch, downsample=True))\n",
    "                self.zero_convs.append(self.make_zero_conv(prev_ch))\n",
    "                self.input_blocks.append(self.cnet_lite_layer(prev_ch, ch))\n",
    "            \n",
    "            # last two embeddings in layer always equal to channel mult\n",
    "            self.zero_convs.append(self.make_zero_conv(ch))\n",
    "            self.input_blocks.append(self.cnet_lite_layer(ch, ch))\n",
    "            self.zero_convs.append(self.make_zero_conv(ch))\n",
    "\n",
    "        # middle block and middle block zero conv\n",
    "        self.middle_block = self.cnet_lite_layer(ch, ch)\n",
    "        self.middle_block_out = self.make_zero_conv(ch)\n",
    "    \n",
    "    # zero convolution layer\n",
    "    def make_zero_conv(self, channels):\n",
    "        return TimestepEmbedSequential(zero_module(conv_nd(self.dims, channels, channels, 1, padding=0)))\n",
    "    \n",
    "    # cnet lite layers \"perform simple convolution, followed by activation\"\n",
    "    def cnet_lite_layer(self, in_channels, out_channels, downsample=False):\n",
    "        if downsample:\n",
    "            return TimestepEmbedSequential(\n",
    "                Downsample(in_channels, use_conv=self.conv_resample, dims=self.dims),\n",
    "                conv_nd(self.dims, in_channels, out_channels, 3, padding=1),\n",
    "                nn.SiLU(),\n",
    "            )\n",
    "        else:\n",
    "            return TimestepEmbedSequential(\n",
    "                conv_nd(self.dims, in_channels, out_channels, 3, padding=1),\n",
    "                nn.SiLU(),\n",
    "            )\n",
    "\n",
    "    def forward(self, x, hint, timesteps, context, **kwargs):\n",
    "\n",
    "        outs = []\n",
    "\n",
    "        # get timestep embedding (not used in controlnet-lite layers here)\n",
    "        # t_emb = timestep_embedding(timesteps, self.model_channels, repeat_only=False)\n",
    "        # emb = self.time_embed(t_emb)\n",
    "        emb = None \n",
    "        # first, create embedding for hint with more complex cnn\n",
    "        guided_hint = self.input_hint_block(hint, emb, context)\n",
    "\n",
    "        # start from hint and go through each layer to create each control embedding\n",
    "        h = guided_hint.type(self.dtype)\n",
    "        # print(f\"guided hint shape: {h.shape}\")\n",
    "        # i = 0\n",
    "        for module, zero_conv in zip(self.input_blocks, self.zero_convs):\n",
    "            h = module(h, emb, context)\n",
    "            # print(f\"module {i} output shape: {h.shape}\")\n",
    "            # i += 1\n",
    "            outs.append(zero_conv(h, emb, context))\n",
    "\n",
    "        h = self.middle_block(h, emb, context)\n",
    "        # print(f\"middle block shape: {h.shape}\")\n",
    "        outs.append(self.middle_block_out(h, emb, context))\n",
    "\n",
    "        return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input hint shape: torch.Size([8, 3, 512, 512])\n",
      "torch.Size([8, 320, 64, 64])\n",
      "torch.Size([8, 320, 64, 64])\n",
      "torch.Size([8, 320, 64, 64])\n",
      "torch.Size([8, 320, 32, 32])\n",
      "torch.Size([8, 640, 32, 32])\n",
      "torch.Size([8, 640, 32, 32])\n",
      "torch.Size([8, 640, 16, 16])\n",
      "torch.Size([8, 1280, 16, 16])\n",
      "torch.Size([8, 1280, 16, 16])\n",
      "torch.Size([8, 1280, 8, 8])\n",
      "torch.Size([8, 1280, 8, 8])\n",
      "torch.Size([8, 1280, 8, 8])\n",
      "torch.Size([8, 1280, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "hint_channels=3\n",
    "batch_size=8\n",
    "in_channels=4\n",
    "model_channels=320\n",
    "image_size=512\n",
    "\n",
    "hint = torch.randn(batch_size, hint_channels, image_size, image_size)\n",
    "\n",
    "cnet = CnetLite(image_size, in_channels, model_channels, hint_channels)\n",
    "\n",
    "print(f\"Input hint shape: {hint.shape}\")\n",
    "\n",
    "output = cnet(None, hint, None, None)\n",
    "\n",
    "for out in output:\n",
    "    print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mel-gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
